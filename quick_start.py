"""
å¿«é€Ÿå¯åŠ¨è„šæœ¬ - è§£å†³å¸¸è§é—®é¢˜
1. è‡ªåŠ¨è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
2. ä¼˜åŒ–æ•°æ®è·å–ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
3. æ™ºèƒ½æ—¥æœŸé€‰æ‹©

ä½¿ç”¨æ–¹æ³•:
    python quick_start.py
"""

import logging
from pathlib import Path
from datetime import datetime, timedelta
import joblib

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def check_model_exists():
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨"""
    possible_paths = [
        Path('data_cache/latest_model.pkl'),
        Path('latest_model.pkl'),
        Path('./cache/latest_model.pkl'),
    ]

    for path in possible_paths:
        if path.exists():
            logger.info(f"âœ“ æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {path}")
            return path

    return None


def train_model_quick():
    """å¿«é€Ÿè®­ç»ƒæ¨¡å‹"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ¤– å¼€å§‹è®­ç»ƒæ¨¡å‹...")
    logger.info("=" * 60)

    from config import Config
    from data_manager import DataManager
    from factor_engine import FactorEngine
    from ml_model import MLModel, WalkForwardTrainer, LabelGenerator

    config = Config()

    # ä½¿ç”¨ç¼“å­˜æ•°æ®
    logger.info("1. åŠ è½½å†å²æ•°æ®ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰...")
    dm = DataManager(config)

    # æŸ¥æ‰¾æœ€æ–°çš„ç¼“å­˜æ–‡ä»¶
    cache_dir = Path(config.data.cache_dir)
    cache_files = list(cache_dir.glob('daily_all_*.pkl'))

    if cache_files:
        # ä½¿ç”¨æœ€æ–°çš„ç¼“å­˜
        latest_cache = max(cache_files, key=lambda p: p.stat().st_mtime)
        logger.info(f"   ä½¿ç”¨ç¼“å­˜: {latest_cache.name}")

        import pandas as pd
        df_daily = pd.read_pickle(latest_cache)

        # æ·»åŠ è¡Œä¸šä¿¡æ¯
        try:
            industry_df = dm.get_industry_data()
            df_daily = df_daily.merge(
                industry_df[['ts_code', 'industry']],
                on='ts_code',
                how='left'
            )
        except:
            pass

        logger.info(f"   âœ“ åŠ è½½å®Œæˆ: {len(df_daily)} æ¡è®°å½•")
    else:
        logger.error("âŒ æœªæ‰¾åˆ°ç¼“å­˜æ•°æ®")
        logger.info("è¯·å…ˆè¿è¡Œä¸€æ¬¡è·å–æ•°æ®:")
        logger.info("  python run_live_strategy_enhanced.py")
        return False

    # åªä½¿ç”¨æœ€è¿‘çš„æ•°æ®æ¥è®­ç»ƒï¼ˆåŠ å¿«é€Ÿåº¦ï¼‰
    logger.info("2. å‡†å¤‡è®­ç»ƒæ•°æ®...")
    recent_dates = sorted(df_daily['trade_date'].unique())[-60:]  # æœ€è¿‘60å¤©
    df_recent = df_daily[df_daily['trade_date'].isin(recent_dates)]
    logger.info(f"   ä½¿ç”¨æœ€è¿‘ {len(recent_dates)} å¤©æ•°æ®")

    # è®¡ç®—å› å­
    logger.info("3. è®¡ç®—å› å­...")
    fe = FactorEngine(config)
    df_with_factors = fe.calculate_all_factors(df_recent)
    logger.info("   âœ“ å› å­è®¡ç®—å®Œæˆ")

    # æ·»åŠ æ ‡ç­¾
    logger.info("4. ç”Ÿæˆæ ‡ç­¾...")
    df_with_labels = LabelGenerator.add_labels(df_with_factors, config)
    logger.info("   âœ“ æ ‡ç­¾ç”Ÿæˆå®Œæˆ")

    # è®­ç»ƒæ¨¡å‹
    logger.info("5. è®­ç»ƒæ¨¡å‹...")
    trainer = WalkForwardTrainer(config)
    X, y = trainer.prepare_data(df_with_labels)

    # å»é™¤NaN
    mask = ~(X.isna().any(axis=1) | y.isna())
    X = X[mask]
    y = y[mask]

    if len(X) < 100:
        logger.error("âŒ è®­ç»ƒæ•°æ®ä¸è¶³")
        return False

    logger.info(f"   è®­ç»ƒæ ·æœ¬æ•°: {len(X)}")

    # å¿«é€Ÿè®­ç»ƒ
    model = MLModel(config)
    model.build_model()

    from sklearn.model_selection import train_test_split
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    model.train(X_train, y_train, X_val, y_val)

    # ä¿å­˜æ¨¡å‹
    model_path = Path(config.data.cache_dir) / 'latest_model.pkl'
    model_path.parent.mkdir(parents=True, exist_ok=True)
    model.save(str(model_path))

    logger.info(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")
    return True


def optimize_data_fetching():
    """ä¼˜åŒ–æ•°æ®è·å–ç­–ç•¥"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š æ•°æ®è·å–ä¼˜åŒ–å»ºè®®")
    logger.info("=" * 60)

    print("""
Tushareé™æµé—®é¢˜è§£å†³æ–¹æ¡ˆ:

1. ã€æ¨èã€‘ä½¿ç”¨ç¼“å­˜æ•°æ®
   - ä½ å·²ç»æœ‰ç¼“å­˜: data_cache/daily_all_20250925_20251224.pkl
   - ç›´æ¥ä½¿ç”¨ç¼“å­˜ï¼Œæ— éœ€é‡æ–°è·å–

2. å‡å°‘è·å–å¤©æ•°
   - å½“å‰: --lookback 90 (å¤ªå¤š)
   - å»ºè®®: --lookback 30 (è¶³å¤Ÿ)

3. å‡çº§Tushareè´¦æˆ·
   - å…è´¹è´¦æˆ·: 120æ¬¡/åˆ†é’Ÿï¼ˆå¤ªæ…¢ï¼‰
   - ä»˜è´¹è´¦æˆ·: 500æ¬¡/åˆ†é’Ÿï¼ˆå¿«å¾ˆå¤šï¼‰
   - é“¾æ¥: https://tushare.pro/register?reg=408347

4. æœ¬åœ°ç¼“å­˜ä¼˜å…ˆ
   - ä¿®æ”¹ config.py: use_cache = True âœ“ï¼ˆå·²è®¾ç½®ï¼‰
   - åªè·å–å¢é‡æ•°æ®
    """)


def check_cache_freshness():
    """æ£€æŸ¥ç¼“å­˜æ–°é²œåº¦"""
    cache_dir = Path('data_cache')

    if not cache_dir.exists():
        return None

    cache_files = list(cache_dir.glob('daily_all_*.pkl'))

    if not cache_files:
        return None

    latest_cache = max(cache_files, key=lambda p: p.stat().st_mtime)

    # è§£ææ—¥æœŸ
    import re
    match = re.search(r'_(\d{8})\.pkl', latest_cache.name)
    if match:
        cache_date = match.group(1)
        cache_dt = datetime.strptime(cache_date, '%Y%m%d')
        days_old = (datetime.now() - cache_dt).days

        return {
            'path': latest_cache,
            'date': cache_date,
            'days_old': days_old
        }

    return None


def run_with_cache():
    """ä½¿ç”¨ç¼“å­˜è¿è¡Œå¢å¼ºé€‰è‚¡"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸš€ ä½¿ç”¨ç¼“å­˜å¿«é€Ÿè¿è¡Œ")
    logger.info("=" * 60)

    cache_info = check_cache_freshness()

    if not cache_info:
        logger.error("âŒ æœªæ‰¾åˆ°ç¼“å­˜æ•°æ®")
        return False

    logger.info(f"âœ“ æ‰¾åˆ°ç¼“å­˜: {cache_info['path'].name}")
    logger.info(f"  ç¼“å­˜æ—¥æœŸ: {cache_info['date']}")
    logger.info(f"  å·²ç¼“å­˜: {cache_info['days_old']} å¤©")

    if cache_info['days_old'] > 7:
        logger.warning(f"âš ï¸  ç¼“å­˜è¾ƒæ—§ï¼ˆ{cache_info['days_old']}å¤©ï¼‰")
        logger.info("å»ºè®®è·å–æœ€æ–°æ•°æ®ï¼ˆä½†ä¼šå¾ˆæ…¢ï¼‰")

    # ç›´æ¥è¿è¡Œé€‰è‚¡
    logger.info("\nå¼€å§‹é€‰è‚¡...")

    from config import Config
    from data_manager import DataManager
    from factor_engine import FactorEngine
    from ml_model import MLModel, WalkForwardTrainer
    from enhanced_live_strategy import EnhancedLiveStrategy
    import pandas as pd

    config = Config()

    # åŠ è½½ç¼“å­˜
    logger.info("1. åŠ è½½ç¼“å­˜æ•°æ®...")
    df_history = pd.read_pickle(cache_info['path'])

    # æ·»åŠ è¡Œä¸š
    dm = DataManager(config)
    try:
        industry_df = dm.get_industry_data()
        df_history = df_history.merge(
            industry_df[['ts_code', 'industry']],
            on='ts_code',
            how='left'
        )
    except:
        pass

    logger.info(f"   âœ“ {len(df_history)} æ¡è®°å½•")

    # è®¡ç®—å› å­
    logger.info("2. è®¡ç®—å› å­...")
    fe = FactorEngine(config)
    df_with_factors = fe.calculate_all_factors(df_history)

    # åŠ è½½æ¨¡å‹
    logger.info("3. åŠ è½½æ¨¡å‹...")
    model_path = check_model_exists()

    if not model_path:
        logger.error("âŒ æœªæ‰¾åˆ°æ¨¡å‹")
        return False

    model = MLModel(config)
    model.model = joblib.load(str(model_path))
    logger.info("   âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")

    # é¢„æµ‹
    logger.info("4. ç”Ÿæˆé¢„æµ‹...")
    latest_date = df_with_factors['trade_date'].max()
    df_latest = df_with_factors[df_with_factors['trade_date'] == latest_date]

    trainer = WalkForwardTrainer(config)
    X, _ = trainer.prepare_data(df_latest)
    preds = model.predict(X)
    df_latest['ml_score'] = preds

    logger.info(f"   âœ“ è¯„åˆ†å®Œæˆ: {len(df_latest)} åªè‚¡ç¥¨")

    # è·å–æŒ‡æ•°
    try:
        index_data = dm.get_index_data('000300.SH', cache_info['date'])
    except:
        index_data = None

    # å¢å¼ºé€‰è‚¡
    logger.info("5. å¢å¼ºé€‰è‚¡...")
    enhanced_strategy = EnhancedLiveStrategy(config)
    selected = enhanced_strategy.select_stocks_enhanced(
        df_date=df_latest,
        df_history=df_with_factors,
        index_data=index_data
    )

    # è¾“å‡ºç»“æœ
    if not selected.empty:
        print("\n" + "=" * 100)
        print(f"ğŸ“‹ {latest_date} é€‰è‚¡ç»“æœ (ä½¿ç”¨ç¼“å­˜)")
        print("=" * 100)

        for _, row in selected.head(15).iterrows():
            print(f"{row['ts_code']:10s} {row.get('name', 'N/A'):10s} "
                  f"è¯„åˆ†:{row.get('composite_score', row['ml_score']):.3f} "
                  f"çº§åˆ«:{row.get('position_tier', 'B'):>4s} "
                  f"ä»“ä½:{row.get('weight', 0) * 100:5.2f}%")

        print("=" * 100)
        print(f"æ€»è®¡: {len(selected)} åª")

        # ä¿å­˜
        output_dir = Path('output/enhanced_live_recommendations')
        output_dir.mkdir(parents=True, exist_ok=True)

        csv_path = output_dir / f'recommendations_{latest_date}_cached.csv'
        selected.to_csv(csv_path, index=False, encoding='utf-8-sig')
        logger.info(f"\nâœ“ ç»“æœå·²ä¿å­˜: {csv_path}")

        return True
    else:
        logger.warning("æœªé€‰å‡ºè‚¡ç¥¨")
        return False


def main():
    print("\n" + "=" * 70)
    print(" " * 20 + "ğŸš€ å¿«é€Ÿå¯åŠ¨åŠ©æ‰‹")
    print("=" * 70)

    # 1. æ£€æŸ¥æ¨¡å‹
    model_path = check_model_exists()

    if not model_path:
        logger.warning("\nâš ï¸  æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")

        choice = input("\næ˜¯å¦è®­ç»ƒæ¨¡å‹? (y/n): ")
        if choice.lower() == 'y':
            success = train_model_quick()
            if not success:
                logger.error("æ¨¡å‹è®­ç»ƒå¤±è´¥")
                return
        else:
            logger.info("è·³è¿‡æ¨¡å‹è®­ç»ƒ")
            return
    else:
        logger.info(f"\nâœ“ æ¨¡å‹å·²å­˜åœ¨: {model_path}")

    # 2. æ£€æŸ¥ç¼“å­˜
    cache_info = check_cache_freshness()

    if cache_info:
        logger.info(f"âœ“ ç¼“å­˜å·²å­˜åœ¨: {cache_info['date']} ({cache_info['days_old']}å¤©å‰)")

        if cache_info['days_old'] <= 7:
            logger.info("ç¼“å­˜è¾ƒæ–°ï¼Œæ¨èç›´æ¥ä½¿ç”¨")

            choice = input("\nä½¿ç”¨ç¼“å­˜å¿«é€Ÿè¿è¡Œ? (y/n): ")
            if choice.lower() == 'y':
                run_with_cache()
                return

    # 3. æ•°æ®è·å–å»ºè®®
    optimize_data_fetching()

    print("\n" + "=" * 70)
    print("æ¨èæ“ä½œ:")
    print("=" * 70)
    print("""
æ–¹æ¡ˆAï¼ˆæ¨èï¼‰ï¼šä½¿ç”¨ç¼“å­˜
    python quick_start.py  # ç„¶åé€‰ y

æ–¹æ¡ˆBï¼šè·å–æ–°æ•°æ®ï¼ˆæ…¢ï¼‰
    python run_live_strategy_enhanced.py --lookback 30

æ–¹æ¡ˆCï¼šä½¿ç”¨å›æµ‹æ•°æ®
    python main.py --mode backtest
    """)
    print("=" * 70)


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nå·²å–æ¶ˆ")
    except Exception as e:
        logger.error(f"é”™è¯¯: {e}", exc_info=True)